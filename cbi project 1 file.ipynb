{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ab7e08-73ef-44ea-b074-77e3e11df22c",
   "metadata": {},
   "source": [
    "                        firstly we import the dataset from internet by import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e6ae7-1cb9-4b49-9f37-85346ac46f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "documents = newsgroups.data\n",
    "print(\"Number of documents:\", len(documents))\n",
    "print(\"Sample document:\", documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe1f19-67b0-4f12-8c1a-90f61139082f",
   "metadata": {},
   "source": [
    "import some important libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9be48-bcc2-4ed0-a1ac-5569c676a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037af87-a98f-453d-b3d7-9ff399fd5fb7",
   "metadata": {},
   "source": [
    "we will tokenize the all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2b122-cff0-4c6b-947b-8bc57be8bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = newsgroups.data\n",
    "tokenized_documents = [nltk.word_tokenize(doc) for doc in documents]\n",
    "for i, doc in enumerate(tokenized_documents[:5]):  # Print the first 5 documents\n",
    "    print(f\"Document {i+1}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f5873-5a6b-4086-a60a-6301bca92b9f",
   "metadata": {},
   "source": [
    "we will removes the stop words ,punchtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab639be-0099-428d-928c-a60318681718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "preprocessed_documents = []\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for doc in documents:\n",
    "    # Tokenization \n",
    "    tokens = word_tokenize(doc)\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    preprocessed_documents.append(tokens)\n",
    "print(\"Preprocessed Documents:\")\n",
    "print(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde929a-d3dc-4111-aa83-d2fd052d7cef",
   "metadata": {},
   "source": [
    "know we are doing a  convertion of text data to numerical data  for the better understanding of machine by the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f04b3-150c-484f-8226-28fffa309e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "preprocessed_docs_str = [' '.join(doc) for doc in preprocessed_documents]\n",
    "vectorizer = CountVectorizer(max_features=200)\n",
    "X_bow = vectorizer.fit_transform(preprocessed_docs_str)\n",
    "X_bow_array = X_bow.toarray()\n",
    "print(\"Bag of Words (BoW) Representation:\")\n",
    "print(X_bow_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5491ad-d774-426c-9273-ea020a50ac43",
   "metadata": {},
   "source": [
    "know we are doing a  convertion of text data to numerical data  for the better understanding of machine by the tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d025ab-a07b-4670-a057-7bacf363d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_docs_str)\n",
    "print(\"TF-IDF Representation:\")\n",
    "print(X_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6660f40-67c7-4784-9e81-a6ca8c40368c",
   "metadata": {},
   "source": [
    "Apply K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791aec-da1f-4958-9cfd-2c0a8d762222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 200 # Start with a smaller number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_tfidf)\n",
    "print(cluster_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed8f98-8fdf-4aac-a79b-e04c97a2947e",
   "metadata": {},
   "source": [
    "Evaluation:use metrics like silhouette score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53065c51-1d2c-44e0-845e-135c9d909988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_avg = silhouette_score(X_tfidf, cluster_labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21948c-e4a3-4926-940f-ac64385c9017",
   "metadata": {},
   "source": [
    "Interpret:by the pca process to create a matrix \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc09bf-a96a-42da-b54d-44b6ab750da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "tfidf_matrix_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "print(tfidf_matrix_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30721902-56bc-4c4c-a283-afd64997d1d4",
   "metadata": {},
   "source": [
    "plot a graph of pca for visualialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a9455-33ba-4521-afe6-99d121f58b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(tfidf_matrix_pca[:, 0], tfidf_matrix_pca[:, 1], c=cluster_labels, cmap='viridis')\n",
    "plt.title('K-means Clustering of 20 Newsgroups Dataset')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8d33e-fb80-434e-b3f6-2e632d4737c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster_label in range(num_clusters):\n",
    "    plt.scatter(tfidf_matrix_pca[cluster_labels == cluster_label, 0],\n",
    "                tfidf_matrix_pca[cluster_labels == cluster_label, 1],\n",
    "                label=f'Cluster {cluster_label + 1}')\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], marker='x', s=200, c='k', label='Centroids')\n",
    "plt.title('K-means Clustering of 20 Newsgroups Dataset (PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a14dc-1e6b-49df-9932-90155d02b14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d636b-978f-4c63-96c3-d72e43f3bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df89f3c-6c8b-447b-8a1c-b2607689bb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43479755-da27-4df7-b433-99f1aaaed438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8e6fa-27c0-48f5-9e6f-0c7a640fce6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ab985-2f9d-48f6-8a53-9b0a310aeb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bf619-f0a9-4790-88c6-d21f1985d5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dfad3-889f-44e4-9f1f-38998f398050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c54c7-6153-4d14-b9d6-b036b4047a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
